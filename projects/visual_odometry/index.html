<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Visual Odometry on KITTI Dataset | Shail Dalal Portfolio</title> <meta name="author" content="Shail Dalal"> <meta name="description" content="visual odometry setup on the Kitti dataset on python"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sdalal1.github.io/projects/visual_odometry/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Shail Dalal Portfolio</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Visual Odometry on KITTI Dataset</h1> <p class="post-description">visual odometry setup on the Kitti dataset on python</p> </header> <article> <h1 id="project--visual-odometry-report-summary">Project : Visual Odometry Report Summary</h1> <h1 id="visual-odometry-overview">Visual Odometry Overview</h1> <h2 id="introduction">Introduction</h2> <p>Visual Odometry (VO) is a technique used to estimate a robot’s position and orientation by analyzing the motion of visual features captured by a camera over time. VO plays a crucial role in autonomous navigation systems, enabling robots to understand their environment without relying on external references like GPS.</p> <p>For this project, a complete pipeline of Visual odometry was created and implemented on the Kitti Dataset which ius used for benchmarking tasks like Visual odometry, 3D object Detection and scene understanding. The code was developed in Python using primarily basic packages and OpenCV. While Python is typically not used for real-time applications due to its slower processing capabilities, it excels in visualization and offers a vast array of powerful libraries.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <div class="embed-container"> <iframe width="640" height="390" src="https://www.youtube.com/embed/2FxoWn2sxzM" frameborder="0" allowfullscreen=""></iframe> </div> <style>.embed-container{position:relative;padding-bottom:56.25%;height:0;overflow:hidden;max-width:100%;max-height:80%}.embed-container iframe,.embed-container object,.embed-container embed{position:absolute;top:0;left:0;width:100%;height:100%}</style> </div> </div> <p><br></p> <h2 id="methods">Methods</h2> <p>The visual odometry pipeline was performed on the grayscale images from the dataset. The entire pipeline consisted of following steps</p> <h5 id="disparity-map"><ins>Disparity Map</ins></h5> <p>Taking images from both the left and right camera and create a complete image with features being enhanced. There are two methods used, one is Stereo BM (Block Model) and Stereo SGBM (Semi-Global Block Model). These models are used to convert the images from a stereo setup to a disparity map.</p> <div class="row"> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/disparity_BM-480.webp 480w,/assets/img/disparity_BM-800.webp 800w,/assets/img/disparity_BM-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/disparity_BM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Raw terrain" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> BM Disparity Map </div> </div> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/disparity_SGBM-480.webp 480w,/assets/img/disparity_SGBM-800.webp 800w,/assets/img/disparity_SGBM-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/disparity_SGBM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple Actors Training" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> SGBM Disparity Map </div> </div> </div> <h5 id="depth-map"><ins>Depth Map</ins></h5> <p>One of the important feature which needs to be recovered is the depth. This is done using the stereo camera setup and the disparity map generated. For each pixel, the depth is calculate using the formula Z = fb/d.</p> <ul> <li>Here Z = Depth, f = focal distance of the camera, b = baseline distance between two cameras and d = disparity between two pixels. This formula is generated using simple geometry from the image below.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-2 mt-md-0"> <style>.center-img{display:block;margin-left:auto;margin-right:auto}</style> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Stereo_setup-480.webp 480w,/assets/img/Stereo_setup-800.webp 800w,/assets/img/Stereo_setup-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Stereo_setup.png" class="center-img" width="40%" height="auto" title="Raw terrain" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>This formula implemented on both the types of disparity maps to generate a depth map. The center of the image can be seen to have the least disparity but higher depth information.</p> <div class="row"> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/depth_map_BM-480.webp 480w,/assets/img/depth_map_BM-800.webp 800w,/assets/img/depth_map_BM-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/depth_map_BM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Raw terrain" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> BM Depth Map </div> </div> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/depth_map_SGBM-480.webp 480w,/assets/img/depth_map_SGBM-800.webp 800w,/assets/img/depth_map_SGBM-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/depth_map_SGBM.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple Actors Training" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> SGBM Depth Map </div> </div> </div> <h5 id="feature-extraction"><ins>Feature Extraction</ins></h5> <p>The information from the depth map and the disparity map is used to extract important features. These features are supposed to be change invariant where they are matched with the features extracted from the next frame.</p> <p>The two ways I implemented this was using SIFT and ORB feature detection. More information about them could be found in the attached report.</p> <div class="row"> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SIFT_feature-480.webp 480w,/assets/img/SIFT_feature-800.webp 800w,/assets/img/SIFT_feature-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/SIFT_feature.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Raw terrain" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> SIFT Feature Detection </div> </div> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Orb_feature-480.webp 480w,/assets/img/Orb_feature-800.webp 800w,/assets/img/Orb_feature-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Orb_feature.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple Actors Training" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Orb Feature Detection </div> </div> </div> <h5 id="feature-matching"><ins>Feature Matching</ins></h5> <p>From the features that are detected, we pick two frames one after the other and match the features. This matching is then used to estimate the change in position.</p> <div class="row"> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Sift_feature_matching-480.webp 480w,/assets/img/Sift_feature_matching-800.webp 800w,/assets/img/Sift_feature_matching-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Sift_feature_matching.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Raw terrain" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> SIFT Feature Matching </div> </div> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Orb_feature_matching-480.webp 480w,/assets/img/Orb_feature_matching-800.webp 800w,/assets/img/Orb_feature_matching-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Orb_feature_matching.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple Actors Training" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Orb Feature Matching </div> </div> </div> <h2 id="results">Results</h2> <p>For my results, the SIFT matching worked really well while the ORB error keeps on accumulating. The results are as follows.</p> <table> <thead> <tr> <th> </th> <th>SIFT (Dataset 01)</th> <th>ORB (Dataset 01)</th> </tr> </thead> <tbody> <tr> <td>MAE</td> <td>911.82</td> <td>2891.26</td> </tr> <tr> <td>Time</td> <td>3m 0.32 s</td> <td>1m 37.23 s</td> </tr> <tr> <td>Time/Frame</td> <td>0.167 s</td> <td>0.08831 s</td> </tr> </tbody> </table> <p>The final pictures are below:</p> <div class="row"> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/trajectory_03_sift-480.webp 480w,/assets/img/trajectory_03_sift-800.webp 800w,/assets/img/trajectory_03_sift-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/trajectory_03_sift.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Raw terrain" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> SIFT </div> </div> <div class="col"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/trajectory_03_orb-480.webp 480w,/assets/img/trajectory_03_orb-800.webp 800w,/assets/img/trajectory_03_orb-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/trajectory_03_orb.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple Actors Training" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Orb </div> </div> </div> <h2 id="challenges">Challenges</h2> <p>Several challenges are associated with Visual Odometry:</p> <ul> <li> <strong>Scale Ambiguity:</strong> Without additional sensors, VO struggles with absolute scale, making it difficult to distinguish between a small object close to the camera and a large object far away.</li> <li> <strong>Illumination Changes:</strong> Variations in lighting can impact feature detection and tracking.</li> <li> <strong>Motion Blur:</strong> Fast movement can cause blur, leading to inaccurate feature detection.</li> </ul> <h2 id="possible-improvements">Possible Improvements</h2> <ul> <li>Integrate the Lidar data with a filter to estimate the pose better</li> <li>Use Mapping techniques to improve trajectory estimate</li> </ul> <h2 id="applications">Applications</h2> <p>Visual Odometry is applied in various domains, including:</p> <ul> <li> <strong>Autonomous Vehicles:</strong> Used for navigation in environments where GPS signals are unreliable.</li> <li> <strong>Robotics:</strong> Enables mobile robots to navigate complex environments.</li> <li> <strong>Augmented Reality:</strong> Helps align virtual objects with the real world by tracking the user’s movement.</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>While Visual Odometry is a powerful tool for estimating motion, it is often complemented by other sensors, such as IMUs or LiDAR, to address its limitations. Integrating Visual Odometry with other SLAM (Simultaneous Localization and Mapping) techniques enhances robustness, especially in dynamic and unstructured environments.</p> <h2 id="acknowledgments">Acknowledgments</h2> <ul> <li>Worked With : <a href="https://graham-clifford.com/" rel="external nofollow noopener" target="_blank">Graham Clifford</a> </li> <li>Kitti Dataset</li> <li>Inspiration - <a href="https://www.youtube.com/playlist?list=PLrHDCRerOaI9HfgZDbiEncG5dx7S3Nz6X" rel="external nofollow noopener" target="_blank">Visual Odometry for Beginners</a> </li> </ul> <h2 id="links">Links</h2> <p>Github - <a href="https://github.com/sdalal1/Computer_vision_projects/tree/main/computer_vision_final_project" rel="external nofollow noopener" target="_blank">Computer Vision Project</a> Report - <a href="/assets/pdf/Visual%20Odometry%20Report.pdf">Visual Odometry Report</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Shail Dalal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>